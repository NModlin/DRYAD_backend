# DRYAD.AI Backend - GPU-Enabled Docker Compose Configuration
# Requires NVIDIA Docker runtime for GPU acceleration

version: '3.8'

services:
  # DRYAD.AI Backend Application with GPU Support
  gremlins-api:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      target: production
    container_name: gremlins-api-gpu
    ports:
      - "8000:8000"
    environment:
      # Database
      - DATABASE_URL=sqlite:///app/data/DRYAD.AI.db
      
      # LLM Configuration with GPU
      - LLM_PROVIDER=${LLM_PROVIDER:-llamacpp}
      - LLAMACPP_MODEL=${LLAMACPP_MODEL:-tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf}
      - FORCE_CPU=${FORCE_CPU:-false}  # Allow GPU acceleration
      
      # Vector Database
      - WEAVIATE_URL=http://weaviate:8080
      - WEAVIATE_API_KEY=${WEAVIATE_API_KEY:-}
      
      # Task Queue
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # Security
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:?JWT_SECRET_KEY is required}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID:-}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET:-}
      
      # Application
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      weaviate:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Weaviate Vector Database
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: weaviate
    ports:
      - "8081:8080"  # Changed from 8080 to 8081 to avoid conflict with backend
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Redis for Task Queue
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Celery Worker with GPU Access
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      target: production
    container_name: celery-worker-gpu
    command: celery -A app.core.celery_app worker --loglevel=info --concurrency=2
    environment:
      # Database
      - DATABASE_URL=sqlite:///app/data/DRYAD.AI.db
      
      # Task Queue
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # LLM Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-llamacpp}
      - FORCE_CPU=${FORCE_CPU:-false}
      
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # Celery Beat Scheduler
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      target: production
    container_name: celery-beat
    command: celery -A app.core.celery_app beat --loglevel=info
    environment:
      # Database
      - DATABASE_URL=sqlite:///app/data/DRYAD.AI.db
      
      # Task Queue
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

volumes:
  weaviate_data:
    driver: local
  redis_data:
    driver: local

networks:
  default:
    name: DRYAD.AI-gpu-network
