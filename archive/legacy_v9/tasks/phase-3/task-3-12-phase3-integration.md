# Task 3-12: Phase 3 Integration & Validation

**Phase:** 3 - Advanced Collaboration & Governance  
**Week:** 16  
**Estimated Hours:** 8 hours  
**Priority:** HIGH  
**Dependencies:** All Phase 3 tasks (3-01 through 3-11)

---

## ðŸŽ¯ OBJECTIVE

Integrate all Phase 3 components (GAD workflow, Task Forces, Security, Validation) and perform comprehensive end-to-end testing to ensure the complete Advanced Collaboration & Governance system works as designed.

---

## ðŸ“‹ REQUIREMENTS

### Functional Requirements
- Complete GAD lifecycle (Plan-Review-Execute-Remember) working end-to-end
- Task Forces operational with multi-agent collaboration
- Security protocols enforced across all components
- Validation gauntlet integrated into execution flow
- Elder Approval workflow functional
- HITL consultation working
- Peer handoff operational

### Technical Requirements
- Integration tests for all workflows
- E2E tests for complete scenarios
- Performance benchmarking
- Security testing
- Load testing

### Performance Requirements
- Complete GAD cycle: <30 minutes (simple task)
- Task Force collaboration: <15 minutes
- Validation gauntlet: <10 minutes

---

## ðŸ”§ IMPLEMENTATION STEPS

### Step 1: Create Integration Tests (6 hours)

**File:** `tests/integration/test_phase3_integration.py`

```python
"""
Phase 3 Integration Tests
End-to-end testing of Advanced Collaboration & Governance.
"""

import pytest
from uuid import uuid4

from app.core.gad_workflow import GADWorkflowOrchestrator
from app.services.architect_agent import PathFinderAgent
from app.services.plan_sanity_check import SageAgent
from app.services.protected_clearing import ProtectedClearingService
from app.services.memory_grove import MemoryGroveService


@pytest.fixture
async def gad_orchestrator(
    path_finder,
    sage,
    protected_clearing,
    memory_grove,
    db_session,
):
    """Create GAD workflow orchestrator."""
    return GADWorkflowOrchestrator(
        path_finder=path_finder,
        sage=sage,
        protected_clearing=protected_clearing,
        memory_grove=memory_grove,
        db_session=db_session,
    )


@pytest.mark.asyncio
@pytest.mark.integration
async def test_complete_gad_workflow(gad_orchestrator):
    """
    Test complete GAD workflow end-to-end.
    
    Scenario:
    1. Submit natural language request
    2. Path Finder generates plan
    3. Sage assesses risk
    4. Plan approved (Tier 1 auto-approve)
    5. Execute in Protected Clearing
    6. Store results in Memory Grove
    """
    request = "Add logging to the user authentication endpoint"
    
    # Execute complete workflow
    result = await gad_orchestrator.execute_workflow(
        request=request,
        auto_approve_tier1=True,
    )
    
    # Verify workflow completed
    assert result.status == "COMPLETED"
    assert result.plan is not None
    assert result.assessment is not None
    assert result.execution_result is not None
    
    # Verify plan was generated
    assert len(result.plan.steps) > 0
    
    # Verify risk assessment
    assert result.assessment.risk_tier in ["TIER_1", "TIER_2", "TIER_3"]
    
    # Verify execution
    assert result.execution_result.get("success") is not None


@pytest.mark.asyncio
@pytest.mark.integration
async def test_task_force_collaboration():
    """
    Test Task Force multi-agent collaboration.
    
    Scenario:
    1. Create task force with multiple agents
    2. Agents collaborate on complex problem
    3. Reach consensus
    4. Synthesize solution
    """
    from app.services.task_force_orchestration import (
        TaskForceOrchestrator,
        TaskForceConfig,
        TaskForceType,
    )
    
    orchestrator = TaskForceOrchestrator(
        oracle_service=mock_oracle,
        db_session=mock_db,
    )
    
    config = TaskForceConfig(
        name="Security Review Task Force",
        task_force_type=TaskForceType.EXPEDITION,
        problem_statement="Review authentication system for vulnerabilities",
        required_capabilities=["security", "code_analysis"],
        max_agents=3,
        max_rounds=5,
    )
    
    agent_ids = ["security_agent", "code_analyst", "architect"]
    
    task_force_id = await orchestrator.create_task_force(config, agent_ids)
    
    result = await orchestrator.execute_task_force(
        task_force_id=task_force_id,
        config=config,
        agent_ids=agent_ids,
    )
    
    # Verify collaboration
    assert result.success is True
    assert result.consensus_score >= 0.8
    assert len(result.participating_agents) == 3
    assert result.message_count > 0


@pytest.mark.asyncio
@pytest.mark.integration
async def test_security_enforcement():
    """
    Test security protocols enforcement.
    
    Scenario:
    1. Attempt action without authentication
    2. Verify rejection
    3. Authenticate with valid token
    4. Verify success
    5. Check audit log
    """
    from app.core.security import security_service, IdentityType, Permission
    
    # Create token
    token = security_service.create_access_token(
        subject="test_user",
        identity_type=IdentityType.HUMAN,
        permissions=[Permission.READ, Permission.WRITE],
    )
    
    # Verify token
    payload = security_service.verify_token(token)
    
    assert payload.sub == "test_user"
    assert Permission.READ in payload.permissions
    
    # Check permission
    has_permission = security_service.check_permission(
        payload,
        Permission.WRITE,
    )
    
    assert has_permission is True
    
    # Log audit event
    await security_service.log_audit_event(
        identity_id="test_user",
        identity_type=IdentityType.HUMAN,
        action="TEST_ACTION",
        resource="test_resource",
        result="SUCCESS",
    )


@pytest.mark.asyncio
@pytest.mark.integration
async def test_validation_gauntlet():
    """
    Test Augmented Validation Protocol.
    
    Scenario:
    1. Run complete validation gauntlet
    2. Verify all checks execute
    3. Verify comprehensive report
    """
    from app.services.augmented_validation import AugmentedValidationService
    from pathlib import Path
    
    service = AugmentedValidationService(
        project_root=Path("."),
        min_coverage=80.0,
    )
    
    report = await service.run_full_validation()
    
    # Verify all checks ran
    assert report.total_checks >= 4  # At least 4 checks
    
    # Verify report completeness
    assert report.execution_time_seconds > 0
    assert report.passed_checks + report.failed_checks == report.total_checks


@pytest.mark.asyncio
@pytest.mark.integration
async def test_peer_handoff_chain():
    """
    Test peer-to-peer handoff chain.
    
    Scenario:
    1. Agent A starts task
    2. Hands off to Agent B
    3. Agent B hands off to Agent C
    4. Verify complete chain tracked
    """
    from app.services.peer_handoff import (
        PeerHandoffService,
        HandoffContext,
        HandoffResult,
        AgentCapability,
    )
    
    service = PeerHandoffService()
    
    # Register agents
    async def mock_handler(context: HandoffContext) -> HandoffResult:
        return HandoffResult(
            handoff_id=context.handoff_id,
            success=True,
            result_data={"processed_by": context.to_agent},
            execution_time_seconds=0.1,
        )
    
    service.register_agent(
        agent_id="agent_a",
        agent_name="Agent A",
        capabilities=[AgentCapability.CODE_ANALYSIS],
        handler=mock_handler,
    )
    
    service.register_agent(
        agent_id="agent_b",
        agent_name="Agent B",
        capabilities=[AgentCapability.SECURITY_AUDIT],
        handler=mock_handler,
    )
    
    # Execute handoff
    chain_id = uuid4()
    context = HandoffContext(
        chain_id=chain_id,
        from_agent="orchestrator",
        to_agent="agent_a",
        task_description="Analyze code",
        chain_depth=0,
    )
    
    result = await service.handoff_to_peer(context)
    
    assert result.success is True
    
    # Verify chain tracked
    chain = service.get_handoff_chain(chain_id)
    assert len(chain) > 0
```

### Step 2: Create E2E Test Scenarios (2 hours)

**File:** `tests/e2e/test_complete_scenarios.py`

```python
"""End-to-end test scenarios for Phase 3."""

import pytest


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_high_risk_plan_with_elder_approval():
    """
    Complete scenario: High-risk plan requiring Elder approval.
    
    Flow:
    1. Submit request for security-critical change
    2. Path Finder generates plan
    3. Sage identifies as Tier 3 (high risk)
    4. Elder Approval requested
    5. Human reviews and approves
    6. Execute in Protected Clearing
    7. Run validation gauntlet
    8. Store in Memory Grove
    """
    # Implementation would test complete flow
    pass


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_task_force_with_hitl_consultation():
    """
    Complete scenario: Task Force with HITL consultation.
    
    Flow:
    1. Create Task Force for complex problem
    2. Agents collaborate
    3. Human joins consultation
    4. Agents answer questions
    5. Reach consensus
    6. Execute solution
    """
    # Implementation would test complete flow
    pass
```

---

## âœ… DEFINITION OF DONE

- [ ] All integration tests passing
- [ ] E2E scenarios validated
- [ ] Performance benchmarks met
- [ ] Security testing complete
- [ ] Load testing complete
- [ ] Documentation updated
- [ ] Phase 3 sign-off obtained

---

## ðŸ“Š SUCCESS METRICS

- Integration test pass rate: 100%
- E2E test pass rate: 100%
- Performance targets met: 100%
- Security vulnerabilities: 0
- Test coverage: >85%

---

**Estimated Completion:** 8 hours  
**Assigned To:** QA Lead + Integration Team  
**Status:** NOT STARTED

