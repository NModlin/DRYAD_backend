# Task 3-01: Path Finder (Architect Agent) Implementation

**Phase:** 3 - Advanced Collaboration & Governance  
**Week:** 13  
**Estimated Hours:** 16 hours  
**Priority:** CRITICAL  
**Dependencies:** Phase 2 complete (Agent Swarm operational)

---

## ðŸŽ¯ OBJECTIVE

Implement the Path Finder (Architect Agent) as the core component of the GAD lifecycle's **Plan** phase. This Tier 2 Specialist agent analyzes code context, queries the Memory Grove for historical solutions, and generates comprehensive YAML-based execution plans.

---

## ðŸ“‹ REQUIREMENTS

### Functional Requirements
- Generate execution plans from natural language requests
- Analyze local code context using AST parsing
- Query Memory Grove for relevant historical patterns
- Create structured YAML plan format
- Assess plan complexity and risk level
- Provide alternative approaches when applicable
- Support iterative plan refinement

### Technical Requirements
- Tier 2 Specialist agent with Reasoning LLM (Tier 3)
- Integration with Memory Grove vector database
- AST parsing for code analysis
- YAML plan generation and validation
- Async/await patterns for LLM calls
- Comprehensive error handling
- Structured logging

### Performance Requirements
- Plan generation: <30 seconds for simple tasks
- Plan generation: <2 minutes for complex tasks
- Memory Grove query: <5 seconds
- Code context analysis: <10 seconds

---

## ðŸ”§ IMPLEMENTATION STEPS

### Step 1: Create Path Finder Agent Service (8 hours)

**File:** `app/services/architect_agent.py`

```python
"""
Path Finder (Architect Agent) - GAD Plan Phase Implementation
Generates execution plans from natural language requests with code context analysis.
"""

from __future__ import annotations

import ast
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Any, Self
from uuid import UUID, uuid4

import yaml
from pydantic import BaseModel, Field, field_validator
from structlog import get_logger

from app.core.oracle import OracleService
from app.services.memory_grove import MemoryGroveService
from app.database.models import Agent, ExecutionPlan

logger = get_logger(__name__)


class CodeContext(BaseModel):
    """Code context extracted from repository analysis."""
    
    file_path: Path
    functions: list[str] = Field(default_factory=list)
    classes: list[str] = Field(default_factory=list)
    imports: list[str] = Field(default_factory=list)
    complexity_score: float = Field(ge=0.0, le=100.0)
    
    @field_validator('file_path', mode='before')
    @classmethod
    def validate_path(cls, v: str | Path) -> Path:
        """Ensure file_path is a Path object."""
        return Path(v) if isinstance(v, str) else v


class PlanStep(BaseModel):
    """Individual step in an execution plan."""
    
    step_number: int = Field(ge=1)
    action: str
    target_file: Path | None = None
    method_name: str | None = None
    estimated_hours: float = Field(ge=0.1, le=40.0)
    risk_level: str = Field(pattern=r'^(LOW|MEDIUM|HIGH|CRITICAL)$')
    dependencies: list[int] = Field(default_factory=list)
    validation_criteria: list[str] = Field(default_factory=list)
    
    @field_validator('target_file', mode='before')
    @classmethod
    def validate_target_path(cls, v: str | Path | None) -> Path | None:
        """Ensure target_file is a Path object if provided."""
        if v is None:
            return None
        return Path(v) if isinstance(v, str) else v


class ExecutionPlanModel(BaseModel):
    """Complete execution plan generated by Path Finder."""
    
    plan_id: UUID = Field(default_factory=uuid4)
    request: str
    steps: list[PlanStep]
    total_estimated_hours: float = Field(ge=0.0)
    overall_risk_level: str = Field(pattern=r'^(LOW|MEDIUM|HIGH|CRITICAL)$')
    alternative_approaches: list[str] = Field(default_factory=list)
    prerequisites: list[str] = Field(default_factory=list)
    success_criteria: list[str] = Field(default_factory=list)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    
    def to_yaml(self) -> str:
        """Convert plan to YAML format."""
        plan_dict = self.model_dump(mode='json', exclude={'plan_id', 'created_at'})
        # Convert Path objects to strings for YAML serialization
        for step in plan_dict.get('steps', []):
            if step.get('target_file'):
                step['target_file'] = str(step['target_file'])
        return yaml.dump(plan_dict, default_flow_style=False, sort_keys=False)


class PathFinderAgent:
    """
    Path Finder (Architect Agent) - Tier 2 Specialist
    
    Generates comprehensive execution plans by analyzing code context
    and querying historical patterns from Memory Grove.
    """
    
    def __init__(
        self,
        oracle_service: OracleService,
        memory_grove: MemoryGroveService,
        repository_root: Path,
    ) -> None:
        self.oracle = oracle_service
        self.memory_grove = memory_grove
        self.repository_root = repository_root
        self.logger = logger.bind(agent="path_finder")
    
    async def generate_plan(
        self,
        request: str,
        context_files: list[Path] | None = None,
    ) -> ExecutionPlanModel:
        """
        Generate execution plan from natural language request.
        
        Args:
            request: Natural language description of task
            context_files: Optional list of relevant files for context
            
        Returns:
            Complete execution plan with steps and metadata
            
        Raises:
            ValueError: If request is invalid or plan generation fails
        """
        self.logger.info("generating_plan", request=request[:100])
        
        try:
            # Step 1: Analyze code context
            code_context = await self._analyze_code_context(context_files or [])
            
            # Step 2: Query Memory Grove for similar patterns
            historical_patterns = await self._query_historical_patterns(request)
            
            # Step 3: Generate plan using LLM
            plan = await self._generate_plan_with_llm(
                request=request,
                code_context=code_context,
                historical_patterns=historical_patterns,
            )
            
            # Step 4: Validate and enhance plan
            validated_plan = await self._validate_and_enhance_plan(plan)
            
            self.logger.info(
                "plan_generated",
                plan_id=str(validated_plan.plan_id),
                steps=len(validated_plan.steps),
                total_hours=validated_plan.total_estimated_hours,
            )
            
            return validated_plan
            
        except Exception as e:
            self.logger.error("plan_generation_failed", error=str(e), request=request[:100])
            raise ValueError(f"Failed to generate plan: {e}") from e
    
    async def _analyze_code_context(self, files: list[Path]) -> list[CodeContext]:
        """Analyze code files to extract context."""
        contexts: list[CodeContext] = []
        
        for file_path in files:
            try:
                full_path = self.repository_root / file_path
                if not full_path.exists() or full_path.suffix != '.py':
                    continue
                
                content = full_path.read_text(encoding='utf-8')
                tree = ast.parse(content)
                
                # Extract functions, classes, and imports
                functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                classes = [node.name for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                imports = [
                    node.names[0].name
                    for node in ast.walk(tree)
                    if isinstance(node, (ast.Import, ast.ImportFrom))
                ]
                
                # Calculate complexity (simplified McCabe complexity)
                complexity = sum(
                    1 for node in ast.walk(tree)
                    if isinstance(node, (ast.If, ast.For, ast.While, ast.ExceptHandler))
                )
                
                contexts.append(CodeContext(
                    file_path=file_path,
                    functions=functions,
                    classes=classes,
                    imports=imports,
                    complexity_score=min(complexity * 2.0, 100.0),
                ))
                
            except Exception as e:
                self.logger.warning("code_analysis_failed", file=str(file_path), error=str(e))
        
        return contexts
    
    async def _query_historical_patterns(self, request: str) -> list[dict[str, Any]]:
        """Query Memory Grove for similar historical solutions."""
        try:
            results = await self.memory_grove.semantic_search(
                query=request,
                limit=5,
                filter_type="execution_plan",
            )
            return results
        except Exception as e:
            self.logger.warning("memory_grove_query_failed", error=str(e))
            return []
    
    async def _generate_plan_with_llm(
        self,
        request: str,
        code_context: list[CodeContext],
        historical_patterns: list[dict[str, Any]],
    ) -> ExecutionPlanModel:
        """Generate plan using LLM with context."""
        
        # Build comprehensive prompt
        prompt = self._build_plan_prompt(request, code_context, historical_patterns)
        
        # Call LLM (Tier 3 - Reasoning)
        response = await self.oracle.consult(
            prompt=prompt,
            model_tier="reasoning",  # GPT-4o, Claude 3 Opus
            temperature=0.3,  # Lower temperature for structured output
            max_tokens=4000,
        )
        
        # Parse LLM response into structured plan
        plan_data = self._parse_llm_response(response)
        
        return ExecutionPlanModel(**plan_data)
    
    def _build_plan_prompt(
        self,
        request: str,
        code_context: list[CodeContext],
        historical_patterns: list[dict[str, Any]],
    ) -> str:
        """Build comprehensive prompt for LLM."""
        context_summary = "\n".join([
            f"- {ctx.file_path}: {len(ctx.functions)} functions, {len(ctx.classes)} classes"
            for ctx in code_context
        ])
        
        patterns_summary = "\n".join([
            f"- {pattern.get('description', 'N/A')}"
            for pattern in historical_patterns[:3]
        ])
        
        return f"""You are the Path Finder, an expert software architect agent.

TASK REQUEST:
{request}

CODE CONTEXT:
{context_summary or 'No specific files provided'}

HISTORICAL PATTERNS (similar past solutions):
{patterns_summary or 'No historical patterns found'}

Generate a detailed execution plan in JSON format with the following structure:
{{
    "request": "{request}",
    "steps": [
        {{
            "step_number": 1,
            "action": "Description of action",
            "target_file": "path/to/file.py",
            "method_name": "function_name",
            "estimated_hours": 2.0,
            "risk_level": "MEDIUM",
            "dependencies": [],
            "validation_criteria": ["Test passes", "Code review approved"]
        }}
    ],
    "total_estimated_hours": 8.0,
    "overall_risk_level": "MEDIUM",
    "alternative_approaches": ["Alternative 1", "Alternative 2"],
    "prerequisites": ["Prerequisite 1"],
    "success_criteria": ["Criterion 1", "Criterion 2"]
}}

Ensure:
- Steps are ordered logically with dependencies
- Risk levels are realistic (LOW, MEDIUM, HIGH, CRITICAL)
- Time estimates are accurate
- Validation criteria are specific and measurable
"""
    
    def _parse_llm_response(self, response: str) -> dict[str, Any]:
        """Parse LLM response into plan data."""
        import json
        
        # Extract JSON from response (handle markdown code blocks)
        response = response.strip()
        if response.startswith('```'):
            response = response.split('```')[1]
            if response.startswith('json'):
                response = response[4:]
        
        return json.loads(response.strip())
    
    async def _validate_and_enhance_plan(self, plan: ExecutionPlanModel) -> ExecutionPlanModel:
        """Validate plan structure and enhance with additional checks."""
        
        # Validate step dependencies
        step_numbers = {step.step_number for step in plan.steps}
        for step in plan.steps:
            for dep in step.dependencies:
                if dep not in step_numbers:
                    raise ValueError(f"Step {step.step_number} has invalid dependency: {dep}")
        
        # Recalculate total hours
        total_hours = sum(step.estimated_hours for step in plan.steps)
        plan.total_estimated_hours = total_hours
        
        # Determine overall risk level
        risk_levels = [step.risk_level for step in plan.steps]
        if 'CRITICAL' in risk_levels:
            plan.overall_risk_level = 'CRITICAL'
        elif 'HIGH' in risk_levels:
            plan.overall_risk_level = 'HIGH'
        elif 'MEDIUM' in risk_levels:
            plan.overall_risk_level = 'MEDIUM'
        else:
            plan.overall_risk_level = 'LOW'
        
        return plan
```

### Step 2: Create Tests (4 hours)

**File:** `tests/test_architect_agent.py`

```python
"""Tests for Path Finder (Architect Agent)."""

import pytest
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

from app.services.architect_agent import (
    PathFinderAgent,
    ExecutionPlanModel,
    CodeContext,
    PlanStep,
)


@pytest.fixture
def mock_oracle():
    """Mock Oracle service."""
    oracle = AsyncMock()
    oracle.consult.return_value = """```json
{
    "request": "Add user authentication",
    "steps": [
        {
            "step_number": 1,
            "action": "Create User model",
            "target_file": "app/database/models.py",
            "method_name": null,
            "estimated_hours": 2.0,
            "risk_level": "LOW",
            "dependencies": [],
            "validation_criteria": ["Model tests pass"]
        }
    ],
    "total_estimated_hours": 2.0,
    "overall_risk_level": "LOW",
    "alternative_approaches": [],
    "prerequisites": [],
    "success_criteria": ["Authentication works"]
}
```"""
    return oracle


@pytest.fixture
def mock_memory_grove():
    """Mock Memory Grove service."""
    memory = AsyncMock()
    memory.semantic_search.return_value = []
    return memory


@pytest.fixture
def path_finder(mock_oracle, mock_memory_grove, tmp_path):
    """Create Path Finder agent instance."""
    return PathFinderAgent(
        oracle_service=mock_oracle,
        memory_grove=mock_memory_grove,
        repository_root=tmp_path,
    )


@pytest.mark.asyncio
async def test_generate_plan_success(path_finder, mock_oracle):
    """Test successful plan generation."""
    plan = await path_finder.generate_plan("Add user authentication")
    
    assert isinstance(plan, ExecutionPlanModel)
    assert plan.request == "Add user authentication"
    assert len(plan.steps) == 1
    assert plan.total_estimated_hours == 2.0
    assert plan.overall_risk_level == "LOW"
    
    mock_oracle.consult.assert_called_once()


@pytest.mark.asyncio
async def test_code_context_analysis(path_finder, tmp_path):
    """Test code context extraction."""
    # Create test Python file
    test_file = tmp_path / "test.py"
    test_file.write_text("""
def hello():
    pass

class MyClass:
    def method(self):
        if True:
            pass
""")
    
    contexts = await path_finder._analyze_code_context([Path("test.py")])
    
    assert len(contexts) == 1
    assert "hello" in contexts[0].functions
    assert "MyClass" in contexts[0].classes
    assert contexts[0].complexity_score > 0


@pytest.mark.asyncio
async def test_plan_to_yaml(path_finder, mock_oracle):
    """Test YAML export of plan."""
    plan = await path_finder.generate_plan("Test task")
    yaml_output = plan.to_yaml()
    
    assert "request:" in yaml_output
    assert "steps:" in yaml_output
    assert "Test task" in yaml_output
```

---

## âœ… DEFINITION OF DONE

- [ ] Path Finder agent service implemented with all methods
- [ ] Code context analysis working with AST parsing
- [ ] Memory Grove integration functional
- [ ] LLM-based plan generation operational
- [ ] YAML plan export working
- [ ] All tests passing (>90% coverage)
- [ ] Type hints complete
- [ ] Documentation complete
- [ ] Integration with GAD workflow tested

---

## ðŸ“Š SUCCESS METRICS

- Plan generation success rate: >95%
- Average plan generation time: <45 seconds
- Code context analysis accuracy: >90%
- Memory Grove query success rate: >98%
- Test coverage: >90%

---

**Estimated Completion:** 16 hours  
**Assigned To:** Agent Specialist  
**Status:** NOT STARTED

