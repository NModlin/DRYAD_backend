# ============================================================================
# Fluentd Configuration for GremlinsAI Backend
# Log aggregation and forwarding
# ============================================================================

# ============================================================================
# Source: Docker Container Logs
# ============================================================================
<source>
  @type forward
  @id input_forward
  port 24224
  bind 0.0.0.0
</source>

# ============================================================================
# Source: Application Log Files
# ============================================================================
<source>
  @type tail
  @id input_tail_app
  path /app/logs/gremlinsai.log
  pos_file /var/log/fluentd/gremlinsai.log.pos
  tag app.gremlinsai
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%LZ
  </parse>
</source>

<source>
  @type tail
  @id input_tail_errors
  path /app/logs/errors.log
  pos_file /var/log/fluentd/errors.log.pos
  tag app.errors
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%LZ
  </parse>
</source>

<source>
  @type tail
  @id input_tail_self_healing
  path /app/logs/gremlins_errors.log
  pos_file /var/log/fluentd/gremlins_errors.log.pos
  tag app.self_healing
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%LZ
  </parse>
</source>

# ============================================================================
# Source: Nginx Access Logs
# ============================================================================
<source>
  @type tail
  @id input_tail_nginx_access
  path /var/log/nginx/access.log
  pos_file /var/log/fluentd/nginx-access.log.pos
  tag nginx.access
  <parse>
    @type nginx
  </parse>
</source>

<source>
  @type tail
  @id input_tail_nginx_error
  path /var/log/nginx/error.log
  pos_file /var/log/fluentd/nginx-error.log.pos
  tag nginx.error
  <parse>
    @type regexp
    expression /^(?<time>[^ ]+ [^ ]+) \[(?<log_level>\w+)\] (?<pid>\d+).(?<tid>[^:]+): (?<message>.*)$/
    time_format %Y/%m/%d %H:%M:%S
  </parse>
</source>

# ============================================================================
# Filter: Add Metadata
# ============================================================================
<filter app.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment "#{ENV['ENVIRONMENT'] || 'production'}"
    service "gremlinsai-backend"
  </record>
</filter>

<filter nginx.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment "#{ENV['ENVIRONMENT'] || 'production'}"
    service "nginx"
  </record>
</filter>

# ============================================================================
# Filter: Parse and Enrich
# ============================================================================
<filter app.gremlinsai>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# ============================================================================
# Filter: Detect Errors
# ============================================================================
<filter app.**>
  @type grep
  <regexp>
    key level
    pattern /(ERROR|CRITICAL)/
  </regexp>
  <or>
    <regexp>
      key message
      pattern /exception|error|failed/i
    </regexp>
  </or>
</filter>

# ============================================================================
# Output: Elasticsearch (for log storage and search)
# ============================================================================
<match app.**>
  @type elasticsearch
  @id output_elasticsearch_app
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix gremlinsai-app
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch-app
    flush_mode interval
    flush_interval 10s
    flush_thread_count 2
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_timeout 60m
    overflow_action block
  </buffer>
</match>

<match nginx.**>
  @type elasticsearch
  @id output_elasticsearch_nginx
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix gremlinsai-nginx
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  <buffer>
    @type file
    path /var/log/fluentd/buffer/elasticsearch-nginx
    flush_mode interval
    flush_interval 10s
    flush_thread_count 2
  </buffer>
</match>

# ============================================================================
# Output: S3 (for long-term archival)
# ============================================================================
<match app.** nginx.**>
  @type s3
  @id output_s3
  aws_key_id "#{ENV['AWS_ACCESS_KEY_ID']}"
  aws_sec_key "#{ENV['AWS_SECRET_ACCESS_KEY']}"
  s3_bucket gremlinsai-logs
  s3_region us-east-1
  path logs/%Y/%m/%d/
  time_slice_format %Y%m%d%H
  <buffer time>
    @type file
    path /var/log/fluentd/buffer/s3
    timekey 3600  # 1 hour
    timekey_wait 10m
    chunk_limit_size 256m
  </buffer>
  <format>
    @type json
  </format>
</match>

# ============================================================================
# Output: Stdout (for debugging)
# ============================================================================
<match **>
  @type stdout
  @id output_stdout
</match>

