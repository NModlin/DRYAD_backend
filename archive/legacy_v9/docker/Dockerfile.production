# Production Dockerfile for GremlinsAI Self-Contained AI System
FROM python:3.11-slim

# Set environment variables for production
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    ENVIRONMENT=production \
    USE_LOCAL_LLM=true \
    ENABLE_MULTI_AGENT=true \
    ENABLE_PERFORMANCE_OPTIMIZATION=true

WORKDIR /app

# Install system dependencies for local LLM and performance optimization
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    cmake \
    build-essential \
    libopenblas-dev \
    liblapack-dev \
    pkg-config \
    wget \
    curl \
    htop \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Create directories with proper permissions
RUN mkdir -p /app/models /app/logs /app/data /app/cache && \
    chmod 755 /app/models /app/logs /app/data /app/cache

# Copy requirements and install Python dependencies
COPY requirements-minimal.txt requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Install additional production dependencies
RUN pip install --no-cache-dir \
    gunicorn==21.2.0 \
    uvicorn[standard]==0.24.0 \
    prometheus-client==0.19.0 \
    psutil==5.9.6

# Copy application code
COPY . .

# Create non-root user with proper permissions
RUN groupadd -r appuser && \
    useradd -r -g appuser -u 1000 appuser && \
    chown -R appuser:appuser /app

# Create startup script
RUN cat > /app/start-production.sh << 'EOF'
#!/bin/bash
set -e

echo "ðŸš€ Starting GremlinsAI Production Server..."

# Initialize performance optimizer
echo "ðŸ”§ Initializing performance optimization..."
python -c "
import sys
sys.path.insert(0, '.')
try:
    from app.core.performance_optimizer import performance_optimizer
    performance_optimizer.initialize()
    print('âœ… Performance optimizer initialized')
except Exception as e:
    print(f'âš ï¸  Performance optimizer initialization failed: {e}')
"

# Check model availability
echo "ðŸ¤– Checking AI model availability..."
python -c "
import sys
sys.path.insert(0, '.')
try:
    from app.core.model_manager import model_manager
    recommended = model_manager.get_recommended_model()
    print(f'âœ… Recommended model: {recommended}')
    
    # Pre-download model if not available
    if not model_manager.is_model_available(recommended):
        print('ðŸ“¥ Downloading AI model for first-time setup...')
        model_manager.download_model(recommended)
        print('âœ… Model download completed')
    else:
        print('âœ… Model already available')
except Exception as e:
    print(f'âš ï¸  Model check failed: {e}')
"

# Start the server
echo "ðŸŒ Starting web server..."
exec gunicorn app.main:app \
    --worker-class uvicorn.workers.UvicornWorker \
    --workers 2 \
    --bind 0.0.0.0:8000 \
    --timeout 300 \
    --keep-alive 5 \
    --max-requests 1000 \
    --max-requests-jitter 100 \
    --access-logfile /app/logs/access.log \
    --error-logfile /app/logs/error.log \
    --log-level info \
    --preload
EOF

RUN chmod +x /app/start-production.sh

# Switch to non-root user
USER appuser

# Health check with proper timeout for AI operations
HEALTHCHECK --interval=60s --timeout=45s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Production startup
CMD ["/app/start-production.sh"]
