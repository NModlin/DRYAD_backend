name: DRYAD.AI Backend CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  release:
    types: [ published ]

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: DRYAD.AI/backend

jobs:
  # Code Quality and Security Checks
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies (Unified Installation)
      run: |
        python -m pip install --upgrade pip
        # New unified installation approach
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Test GPU Detection and Auto-Configuration
      env:
        FORCE_CPU: "true"  # Force CPU-only for CI environment
      run: |
        echo "Testing GPU detection in CI environment..."
        python -c "
        from app.core.llm_config import detect_gpu_config
        from app.core.multimodal import get_optimal_device
        import json

        # Test LLM GPU detection
        gpu_config = detect_gpu_config()
        print('LLM GPU Detection Results:')
        print(json.dumps(gpu_config, indent=2))

        # Test multimodal device selection
        device = get_optimal_device()
        print(f'Multimodal optimal device: {device}')

        # Verify CPU-only configuration
        assert gpu_config['device'] == 'cpu', f'Expected CPU, got {gpu_config[\"device\"]}'
        assert gpu_config['n_gpu_layers'] == 0, f'Expected 0 layers, got {gpu_config[\"n_gpu_layers\"]}'
        assert device == 'cpu', f'Expected CPU device, got {device}'

        print('âœ… GPU detection and auto-configuration working correctly')
        "

    - name: Code formatting check (Black)
      run: black --check --diff .
    
    - name: Import sorting check (isort)
      run: isort --check-only --diff .
    
    - name: Linting (flake8)
      run: flake8 app/ tests/ --max-line-length=100 --extend-ignore=E203,W503
    
    - name: Type checking (mypy)
      run: mypy app/ --ignore-missing-imports --no-strict-optional
      continue-on-error: true  # Type checking is advisory for now
    
    - name: Security check (bandit)
      run: |
        bandit -r app/ -f json -o bandit-report.json
        bandit -r app/ --severity-level medium --confidence-level medium
      continue-on-error: false

    - name: Dependency vulnerability check (safety)
      run: |
        safety check --json --output safety-report.json
        safety check --full-report
      continue-on-error: false

    - name: License compliance check
      run: |
        pip-licenses --format=json --output-file=licenses-report.json
        pip-licenses --fail-on="GPL v3"
      continue-on-error: false
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          licenses-report.json

  # Unit and Integration Tests
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [unit, integration, functional]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: DRYAD.AI_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies (Unified Installation)
      run: |
        python -m pip install --upgrade pip
        # New unified installation approach
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Set up test environment
      run: |
        cp .env.example .env.test
        echo "DATABASE_URL=postgresql://postgres:testpassword@localhost:5432/DRYAD.AI_test" >> .env.test
        echo "REDIS_URL=redis://localhost:6379" >> .env.test
        echo "ENVIRONMENT=test" >> .env.test
        echo "JWT_SECRET_KEY=test-secret-key-for-ci" >> .env.test
    
    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        pytest tests/unit/ -v --cov=app --cov-report=xml --cov-report=html
      env:
        ENVIRONMENT: test
    
    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: |
        pytest tests/integration/ -v --cov=app --cov-report=xml --cov-report=html
      env:
        ENVIRONMENT: test
        DATABASE_URL: postgresql://postgres:testpassword@localhost:5432/DRYAD.AI_test
        REDIS_URL: redis://localhost:6379
    
    - name: Run functional tests
      if: matrix.test-type == 'functional'
      run: |
        pytest tests/functional/ -v --cov=app --cov-report=xml --cov-report=html
      env:
        ENVIRONMENT: test
        DATABASE_URL: postgresql://postgres:testpassword@localhost:5432/DRYAD.AI_test
        REDIS_URL: redis://localhost:6379
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: ${{ matrix.test-type }}
        name: codecov-${{ matrix.test-type }}
    
    - name: Upload test artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.test-type }}
        path: |
          htmlcov/
          coverage.xml
          pytest-report.xml

  # Performance and Load Testing
  performance-test:
    runs-on: ubuntu-latest
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies (Unified Installation)
      run: |
        python -m pip install --upgrade pip
        # New unified installation approach
        pip install -r requirements.txt
        pip install locust
    
    - name: Start application
      run: |
        python start.py &
        sleep 30  # Wait for app to start
      env:
        ENVIRONMENT: test
        BASIC_MODE: true
    
    - name: Run performance tests
      run: |
        locust -f tests/performance/locustfile.py --headless -u 10 -r 2 -t 60s --host=http://localhost:8000
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: locust-report.html

  # Build and Push Docker Image
  build:
    runs-on: ubuntu-latest
    needs: [code-quality, test]
    if: github.event_name == 'push' || github.event_name == 'release'
    
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
    
    - name: Build and push Docker image
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64
    
    - name: Generate SBOM
      uses: anchore/sbom-action@v0
      with:
        image: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        format: spdx-json
        output-file: sbom.spdx.json
    
    - name: Upload SBOM
      uses: actions/upload-artifact@v3
      with:
        name: sbom
        path: sbom.spdx.json

  # Security Scanning
  security-scan:
    runs-on: ubuntu-latest
    needs: [build]
    if: github.event_name == 'push' || github.event_name == 'release'
    
    steps:
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [build, security-scan]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add actual deployment commands here
        # Example: kubectl apply -f k8s/staging/
      env:
        KUBECONFIG_DATA: ${{ secrets.STAGING_KUBE_CONFIG }}
        IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
    
    - name: Run smoke tests
      run: |
        echo "Running smoke tests against staging..."
        # Add smoke test commands here
        sleep 30  # Wait for deployment
        curl -f https://staging-api.DRYAD.AI.com/api/v1/health || exit 1
    
    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
      if: always()

  # Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [build, security-scan]
    if: github.event_name == 'release'
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to production
      run: |
        echo "Deploying to production environment..."
        # Add actual deployment commands here
        # Example: kubectl apply -f k8s/production/
      env:
        KUBECONFIG_DATA: ${{ secrets.PRODUCTION_KUBE_CONFIG }}
        IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
    
    - name: Run production health checks
      run: |
        echo "Running production health checks..."
        sleep 60  # Wait for deployment
        curl -f https://api.DRYAD.AI.com/api/v1/health || exit 1
        curl -f https://api.DRYAD.AI.com/api/v1/health/monitoring || exit 1
    
    - name: Update deployment status
      run: |
        echo "Production deployment completed successfully"
        echo "Image: ${{ needs.build.outputs.image-tag }}"
        echo "Digest: ${{ needs.build.outputs.image-digest }}"
    
    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#production'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
      if: always()

  # Cleanup
  cleanup:
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Clean up old images
      run: |
        echo "Cleaning up old container images..."
        # Add cleanup commands here
